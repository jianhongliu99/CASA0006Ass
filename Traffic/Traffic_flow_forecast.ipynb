{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd9fdb2-1340-47f1-8b73-8f3f00698705",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Traffic forecasting using Neural Networks(SAEs、LSTM、GRU)\n",
    "\n",
    "**Author:** JIANHONG LIU<br>\n",
    "**Date created:** 2023/4/1<br>\n",
    "**Last modified:** 2023/4/23<br>\n",
    "**Description:** This example demonstrates how to do timeseries forecasting over Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ae9aa-4fcd-4682-8b67-3f9cda1bcaff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Accurate and real-time traffic flow prediction is crucial in intelligent transportation systems (ITS), especially for traffic control. Existing models such as ARMA, and ARIMA are mainly linear models, which cannot capture the randomness and nonlinearity of traffic flow, leading to poor prediction accuracy.\n",
    "\n",
    "In recent years, deep learning methods have been proposed as a new alternative for traffic flow prediction. However, it is still unclear which type of deep neural network is the most suitable model for traffic flow prediction. In this paper, we use Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and Stacked Autoencoder (SAE) models to predict short-term traffic flow. \n",
    "\n",
    "The experimental results show that all three deep neural network models can effectively predict traffic flow, and their prediction performance is greatly improved compared to traditional linear models such as ARMA. Among these three models, SAE performs slightly better than LSTM and GRU. Specifically, SAE's MAE, MSE, and RMSE metrics are slightly better than those of LSTM and GRU. In addition, SAE's R2 and explained variance score are also slightly higher than those of LSTM and GRU, indicating that SAE has a better fitting effect on the traffic flow data in this article.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4131666c-2f3b-4b62-85bb-e55f4b809402",
   "metadata": {},
   "source": [
    "## Literature review\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a60048-a1bd-4a33-9315-c04fe83ce6d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f220a71-5cb6-4368-b593-72136f016492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a115270-2f4c-46d1-8a5f-629f15a5941d",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56d41b8-afef-4173-9f1e-a61adfd4136d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data description\n",
    "\n",
    "We use a real-world traffic speed dataset named `PeMSD7`. We use the version\n",
    "collected and prepared by [JIANHONG LIU](https://github.com/jianhongliu99/CASA0006/tree/main/data)\n",
    "and available\n",
    "[here](https://github.com/VeritasYin/STGCN_IJCAI-18/tree/master/data_loader).\n",
    "\n",
    "The data consists of two files:\n",
    "\n",
    "- `W_228.csv` contains the distances between 228\n",
    "stations across the District 7 of California.\n",
    "- `V_228.csv` contains traffic\n",
    "speed collected for those stations in the weekdays of May and June of 2012.\n",
    "\n",
    "The full description of the dataset can be found in\n",
    "[Yu et al., 2018](https://arxiv.org/abs/1709.04875).\n",
    "Data are obtained from the Caltrans Performance Measurement System (PeMS). Data are collected in real-time from individual detectors spanning the freeway system across all major metropolitan areas of the State of California.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa6d12-c294-4c80-88bf-75b55e396120",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f02cb3ab-06fe-4556-8664-411a32a2212e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 26, saw 367\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(response\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 加载CSV文件\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 查看数据框\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1255\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1253\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1255\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 225\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    227\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1960\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 26, saw 367\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# 下载CSV文件\n",
    "url = \"https://github.com/jianhongliu99/CASA0006/blob/main/datasets.csv\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# 将CSV文件存储到本地\n",
    "with open(\"datasets.csv\", \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# 加载CSV文件\n",
    "df = pd.read_csv(\"datasets.csv\")\n",
    "\n",
    "# 查看数据框\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3883eaf3-8ce8-4359-8550-3579fcf698de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b330617f-b673-47c7-8fab-83a94d5306b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12096 entries, 0 to 12095\n",
      "Data columns (total 4 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   5 Minutes                    12096 non-null  object\n",
      " 1   Lane 1 Flow (Veh/5 Minutes)  12096 non-null  int64 \n",
      " 2   Lane Points                  12096 non-null  int64 \n",
      " 3    Observed_percent            12096 non-null  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 378.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a5392ac-6392-4269-9ce5-4b0c07c42263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5 Minutes</th>\n",
       "      <th>Lane 1 Flow (Veh/5 Minutes)</th>\n",
       "      <th>Lane Points</th>\n",
       "      <th>Observed_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04/01/2016 00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04/01/2016 00:05</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/01/2016 00:10</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/01/2016 00:15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04/01/2016 00:20</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          5 Minutes  Lane 1 Flow (Veh/5 Minutes)  Lane Points  \\\n",
       "0  04/01/2016 00:00                           12            1   \n",
       "1  04/01/2016 00:05                           13            1   \n",
       "2  04/01/2016 00:10                           11            1   \n",
       "3  04/01/2016 00:15                           13            1   \n",
       "4  04/01/2016 00:20                           10            1   \n",
       "\n",
       "   Observed_percent  \n",
       "0           100.00%  \n",
       "1           100.00%  \n",
       "2           100.00%  \n",
       "3           100.00%  \n",
       "4           100.00%  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd2dda4-7f2e-4cc7-9b69-2537acadb589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
